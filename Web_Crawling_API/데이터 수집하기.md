# 데이터 수집하기:computer:



>  요청은 'URL'
>
> 응답은 ''텍스트 덩어리''



> 요청하는 녀석은 '클라이언트'
>
> 응답하는 녀석은 '서버'





HTML은 사람이 보기 위해 만들어진 텍스트, 예쁘게 나온다.



## 웹 페이지 크롤링

크롤링 : 제공되지 않는 데이터를 수집하기



네이버 증권에서 코스피 지수와 달러 환율 크롤링하기

```python
import requests
from bs4 import BeautifulSoup

url = 'https://finance.naver.com/sise/'

res = requests.get(url)
data = BeautifulSoup(res.text, 'html.parser')
kospi = data.select_one('#KOSPI_now')

print(kospi.text)


usd_url = 'https://finance.naver.com/marketindex/'

usd_res = requests.get(usd_url)
usd_data = BeautifulSoup(usd_res.text, 'html.parser')
usd = usd_data.select_one('#exchangeList > li:nth-child(1) > a.head.usd > div > span.value')
print(usd.text)
```

requests : URL을 요청하기 위한 모듈

BeautifulSoup : 응답받은 텍스트를 전처리하기 위한 모듈



select_one은 해당하는 데이터 하나를 가져오는 함수.

selector를 넣어줘야하는데, 웹페이지에서 찾고 싶은 데이터에서 오른쪽 클릭 후 Copy- > Copy Selector를

누르면 해당 데이터의 selector를 바로 얻어낼 수 있다.



<br/>



## API

**API : Application Programming Interface**

개발자들 위해서 제공하는 데이터

xml 아니면 json으로 데이터를 제공, 요즘은 대부분 json.



로또번호 API를 활용하여 971회차 당첨번호 알아내기

```python
import requests

url = 'https://www.dhlottery.co.kr/common.do?method=getLottoNumber&drwNo=971'
res = requests.get(url)

# print(res.text) 
# 조심 : dict처럼 보이지만 그냥 str임.

data = res.json() # parsing
drwtNos = [f'drwtNo{i}' for i in range(1, 7)]
print('당첨번호 : ', [data[key] for key in drwtNos])
print('보너스 번호 : ',data['bnusNo'])

"""
당첨번호 :  [2, 6, 17, 18, 21, 26]
보너스 번호 :  7
"""
```

`requests.get(url)`로 받은 응답의 `type`은 `str`이다. 

이걸 json 파일로 parsing해주면  `dict`으로 사용가능하다.

